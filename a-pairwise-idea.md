# 高不确定样本对+LLM伪监督信号+对比学习

- 预训练

    - 对于标签数据：CELoss
    - 对于所有数据（有标签+无标签）：MLMLoss
    - 得到：PretrainBert

- 主框架：对比学习

    - 使用预训练模型提取所有样本的特征向量 $I_i$
    - 根据特征向量计算相似度得分 $$S_{ij} = \frac{I_i  I_j}{||I_i||*||I_j||}$$
    - 对于标签数据, $R_{ij}$直接根据标签获得，相同标签取1，不同标签取0
    - 对于无标签数据，设置相似度得分区间上下限 $l(\lambda), u(\lambda)$, 相似度得分大于上限$\bar{R}_{ij}$ 取1，小于下限取0，中间样本对为**高不确定性样本对集合Q**

    - 调用LLM判断高不确定性样本对
        - 输入：样本对
        - 输出：yes/no, 以及置信度得分 $[0, 1]$

    - **$A,N,P$**

        - 如果有标签，那么标签一致为正样本，标签不一致为负样本。如果有多个，正负样本均随机选取

        - 如果没有标签，那么高相似度得分的样本和LLM高置信度判断yes的样本为正样本，同样随机选取一个 *(这里应该是LLM高置信度判断yes的样本更有价值)*

        - LLM高置信度判断no的样本和同一batch内的其他样本为负样本，同样随机选取一个 *(这里应该是LLM高置信度判断no的样本更有价值)*

        - LLM的高置信度也需要判定，事实上，由于三元组损失函数每次只需要选择一个正例和一个负例，因此可以按照置信度得分高低选择，选择置信度最高的样本

    - 损失函数

        - **三元组损失函数**
        $$L(A,P,N) = max\{sim(A,P) - sim(A,N)+margin,~ 0\}$$
            - 难点在于：**难样本**的挖掘
                - 距离小但其实是负类
                - 距离大但其实是正类

            - margin调参
            - 相似度得分越高是否代表样本之间的距离越小？
        
        - **半监督损失**
            - 参考CDAC-plus论文的半监督损失

    - 训练策略

        - 每隔几轮更新集合Q和LLM伪监督信号
        - 早停策略
        - 保存最佳模型

- 评估
    - KMeans
    - 评价指标：NMI，ARI，ACC
    - 匈牙利对齐


# 1026
- 预训练不变
- 