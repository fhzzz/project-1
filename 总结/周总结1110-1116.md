# 1110-1116

### 1112周三
前几天的内容基本都写在了train_log.md文件里。因为觉得现在有点乱，好像有很多需要做的，但是好像又有点无从下手，其实关键应该是我不知道是否应该那样做、会有用吗，如果那样做的话。

我自己改进的问题是，性能总也比不上预训练权重，好像一直在下降，这个问题我应该问问AI。

我看了别人的实验结果，但是感觉差很多

更改阈值选择策略，按照数据分布来选

### 1113-1115周四-周六
一点没学。哈哈。

### 1116周日

至此，确信的一件事情是，只要看了，多少都会有收获。这就是付出时间的重要性吧，前期无法追求高效率，可以堆量。

明天出去学习吧，虽然想在宿舍安安静静的学习，或者明天看心情决定。

- 其实ALUP不懂的运行早晚都要看，感觉今天忽然懂了一点，好像按照自己想运行的命令也没那么难了。今天卡在了 *args.mode* 上。明天大概从这里看

- 因为如果可以运行成功，我就不自己复现了

- 发现大概如下：
    - 梳理了manager这个类，也就是使用对比学习而不使用LLM，需要梳理清楚正类和负例的选取。ALUP和mtp-clnn应该是不一样的。

    - 基本弄懂了MemoryBank类，好像之前看起来觉得那么复杂，现在再看也就那样，所以还是有一些成长的吧。不过这里还差 *mine_nearest_neighbor* 方法。

    - 尽管有时进度会停滞、无限反驳自己，但是之前有用的零碎的想法永远都在，当需要的时候，它们就都出来了，然后就会更好的进入状态。

    - 已经很久没有按周(每天)记录了，但我想，现在好像可以重新拾起了。




